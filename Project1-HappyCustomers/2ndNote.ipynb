{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOU+QTyqvODu1kLI3CUKXkJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinnew9/Apziva_practice_code/blob/main/Project1-HappyCustomers/2ndNote.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2nd Try (~ until July 23th):\n",
        "1. Apply 'Lazy Classifier' (O)\n",
        "2. Choose 3 models, using the report and should able to explain the reasons for choosing those models so that I can justify my reason! ( )\n",
        "3. Train the models separately (O)\n",
        "4. Use the 'gridsearch' and 'randomsearch', check if these can improve the model performances (O)\n",
        "5. Focus on Recall for class0, because it is more important to know why unsatisfied customers are unsatisfied. ( )"
      ],
      "metadata": {
        "id": "RDuCB2Q6m9en"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPDtpQvHmyBs",
        "outputId": "61bc462d-4108-4906-e250-d0575e091742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lazypredict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDsv7_HCnb4u",
        "outputId": "5edae298-2d57-4521-f6d7-b29e3e478fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.13-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.66.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.4.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lazypredict) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost->lazypredict) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\n",
            "Downloading lazypredict-0.2.13-py2.py3-none-any.whl (12 kB)\n",
            "Installing collected packages: lazypredict\n",
            "Successfully installed lazypredict-0.2.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "8hurdb8qnfOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Import"
      ],
      "metadata": {
        "id": "kgu7ZeiToNXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "mwGZZwym5_-F",
        "outputId": "38207546-686c-462e-908a-81ba283edaf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Apziva/1stProject/ACME-HappinessSurvey2020.csv')\n",
        "\n",
        "data = df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6']]\n",
        "target = df[['Y']]"
      ],
      "metadata": {
        "id": "zp0fkZupoAO6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "9e68e0f3-85ae-425a-c1f3-fd7a69a1d5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Apziva/1stProject/ACME-HappinessSurvey2020.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ce84e9094063>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Apziva/1stProject/ACME-HappinessSurvey2020.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X6'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Apziva/1stProject/ACME-HappinessSurvey2020.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seed = random.randint(1000, 9999)\n",
        "seed = 6245\n",
        "print(seed)"
      ],
      "metadata": {
        "id": "4t6pXb1pn61L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Split"
      ],
      "metadata": {
        "id": "eXRejK65oQ29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=seed)"
      ],
      "metadata": {
        "id": "S3q1_VfGn8h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lazy Classifier"
      ],
      "metadata": {
        "id": "k7XuLEUJoSc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LazyClassifier(verbose=0, ignore_warnings = True, custom_metric=None) # force_col_wise=True\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "models"
      ],
      "metadata": {
        "id": "1U3JdsI7njgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling Part 1\n",
        "### Model 1 - ExtraTreeClassifier\n",
        "I choose this model because it showed the highest f1 score at 1st run."
      ],
      "metadata": {
        "id": "1mzekCNeoHJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = ExtraTreesClassifier(random_state = seed)\n",
        "model1.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "39zTV0bTo5wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GridSearch & RandomSearch for Model1"
      ],
      "metadata": {
        "id": "dwNEbFzSo-zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up hyperparameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10], # I picked odd numbers rather than even numbers, because the tree shows the hierarchy\n",
        "    'n_estimators': [10, 50, 100, 200]\n",
        "}\n",
        "# Try to write the reasons right away next to the code so that I can remember, and explain better to the other people (esp in industries).\n",
        "\n",
        "grid_search1 = GridSearchCV(model1, param_grid, cv=5)\n",
        "grid_search1.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Print out the most optimized parameter score\n",
        "print(\"Best Parameters: \", grid_search1.best_params_)\n",
        "print(\"Best Score: \", grid_search1.best_score_)"
      ],
      "metadata": {
        "id": "i_QDF424pAQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {\n",
        "    'max_depth': randint(1, 11),\n",
        "    'n_estimators': randint(10, 201)\n",
        "}\n",
        "\n",
        "# Random Search\n",
        "random_search1 = RandomizedSearchCV(model1, param_distributions=param_dist, n_iter=20, cv=5)\n",
        "random_search1.fit(X_train, y_train)\n",
        "\n",
        "# Print out the most optimized parameter score\n",
        "print(\"Best Parameters: \", random_search1.best_params_)\n",
        "print(\"Best Score: \", random_search1.best_score_)"
      ],
      "metadata": {
        "id": "hBGJ9GOOpRkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions1 = model1.predict(X_test)"
      ],
      "metadata": {
        "id": "kXMq_ATrpS_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions1)\n",
        "conf_matrix = confusion_matrix(y_test, predictions1)\n",
        "class_report = classification_report(y_test, predictions1)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "8ACVnijEpUED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model2 - RandomForest\n",
        "\n",
        "I choose this model because RandomForest is an ensembling learning algorithm for binary classification task"
      ],
      "metadata": {
        "id": "mthZo8X-pXN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestClassifier(random_state = seed)\n",
        "model2.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "cOFG-BJApZmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GridSearch & RandomSearch for Model2"
      ],
      "metadata": {
        "id": "T0bJBDfmpgQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Setting up hyperparameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'n_estimators': [10, 50, 100, 200]\n",
        "}\n",
        "\n",
        "grid_search2 = GridSearchCV(model2, param_grid, cv=5)\n",
        "grid_search2.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Print out the most optimized parameter score\n",
        "print(\"Best Parameters: \", grid_search2.best_params_)\n",
        "print(\"Best Score: \", grid_search2.best_score_)"
      ],
      "metadata": {
        "id": "PZrO4Dx-piCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {\n",
        "    'max_depth': randint(1, 11),\n",
        "    'n_estimators': randint(10, 201)\n",
        "}\n",
        "\n",
        "\n",
        "# Random Search\n",
        "random_search2 = RandomizedSearchCV(model2, param_distributions=param_dist, n_iter=20, cv=5)\n",
        "random_search2.fit(X_train, y_train)\n",
        "\n",
        "# Print out the most optimized parameter score\n",
        "print(\"Best Parameters: \", random_search2.best_params_)\n",
        "print(\"Best Score: \", random_search2.best_score_)"
      ],
      "metadata": {
        "id": "mXxdkDPlpjjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2 = model2.predict(X_test)"
      ],
      "metadata": {
        "id": "2BZDu2NLpk3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions2)\n",
        "conf_matrix = confusion_matrix(y_test, predictions2)\n",
        "class_report = classification_report(y_test, predictions2)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "cyLUcTZLpl_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model3 - LinearSVC"
      ],
      "metadata": {
        "id": "3ZYcYZUipn5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = LinearSVC(random_state = seed)\n",
        "model3.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "sVLzoNYXppZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions3 = model3.predict(X_test)"
      ],
      "metadata": {
        "id": "Q1SJNzKOpwPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions3)\n",
        "conf_matrix = confusion_matrix(y_test, predictions3)\n",
        "class_report = classification_report(y_test, predictions3)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "N1X2sNuzpx9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model4 - LogisticRegression"
      ],
      "metadata": {
        "id": "alv94LNvpzst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = LogisticRegression(random_state = seed)\n",
        "model4.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "pzRiELjKp00H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions4 = model4.predict(X_test)"
      ],
      "metadata": {
        "id": "DxZmW-EJp1tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions4)\n",
        "conf_matrix = confusion_matrix(y_test, predictions4)\n",
        "class_report = classification_report(y_test, predictions4)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "id": "87ZVyWDSp3fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model5 - DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "Gn7UVpDWp5Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf_tree = DecisionTreeClassifier(min_samples_split=0.2, random_state = seed)\n",
        "clf_tree.fit(X_train, y_train)\n",
        "pred = clf_tree.predict(X_train)\n",
        "print('Training Report\\n {}'.format(classification_report(y_train,pred)))\n",
        "print('Training accuracy: {:.3f}'.format(accuracy_score(y_train,pred)))"
      ],
      "metadata": {
        "id": "jUNIr3Xbp6oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusions after 2nd Try:\n",
        "\n",
        "1. When doing GridSearch and RandomSearch, I need to tuned each hyperparameters. Model 3, LinearSVC and Model 4 Logistic also goes compatible with Grid and RandomSearch; I didn't tuned them and maybe that's why I got error.\n",
        "2. Since the tree shows the hierarchy, odd numbers are better than even numbers for ranking.\n",
        "3. The performance did imporved but didnt reached to 73, so I pondered hard and finally tried another model which was DeicisionClassifier. It eventually worked!\n",
        "4. I erase scaler which might affect performance\n",
        "5. Setting up an random_seed might also affect performance\n"
      ],
      "metadata": {
        "id": "Ixxpi3aHp-d-"
      }
    }
  ]
}